# reply_policy.py
from __future__ import annotations
import re, json
from typing import List, Dict, Tuple

# ---- Smalltalk --------------------------------------------------------------
SMALLTALK_KWS = [
    "ì•ˆë…•","ì•ˆë‡½","í•˜ì´","hi","hello","í—¬ë¡œ","í—¤ì´","ë°©ê°€","ã…ã…‡","ê·¸ëƒ¥",
    "ì˜ ì§€ë‚´","ë­í•´","ì‹¬ì‹¬í•´","ì‹¬ì‹¬","ã…ã…","ã…‹ã…‹","êµ¿ëª¨ë‹","êµ¿ë°¤","ì˜ì","ì¢‹ì€ ì•„ì¹¨","ìˆ˜ê³ ","ê³ ë§ˆì›Œ","ë•¡í","ê°ì‚¬","thanks","thx","ã„³",
    "í…ŒìŠ¤íŠ¸"
]
def is_smalltalk(text: str) -> bool:
    t = (text or "").strip().lower()
    return any(k in t for k in SMALLTALK_KWS)

def smalltalk_reply(text: str) -> str:
    t = (text or "").lower()
    if any(k in t for k in ["ì•ˆë…•","ì•ˆë‡½","í•˜ì´","hello","hi","í—¬ë¡œ","í—¤ì´","ë°©ê°€","ã…ã…‡"]):
        return "ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš” ğŸ˜Š ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    if any(k in t for k in ["êµ¿ëª¨ë‹","ì¢‹ì€ ì•„ì¹¨"]):
        return "ì•ˆë…•í•˜ì„¸ìš”! ì˜ ì§€ë‚´ì…¨ë‚˜ìš”? ğŸ˜Š ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    if any(k in t for k in ["êµ¿ë°¤","ì˜ì"]):
        return "ê³ ë§ˆì›Œìš”! í¸ì•ˆí•œ ë°¤ ë˜ì„¸ìš” ğŸŒ›"
    if any(k in t for k in ["ê³ ë§ˆì›Œ","ê°ì‚¬","ë•¡í","thx","thanks","ìˆ˜ê³ ","ã„³"]):
        return "ë³„ë§ì”€ì„ìš”! ë„ì›€ì´ ë˜ì–´ ê¸°ë»ìš”. ë˜ ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”."
    if any(k in t for k in ["ë­í•´","ì‹¬ì‹¬í•´","ì‹¬ì‹¬"]):
        return "ì—¬ê¸° ìˆì–´ìš”! ì§ˆë¬¸ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì´ì—ìš”. ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"
    if any(k in t for k in ["ã…ã…","ã…‹ã…‹","ê·¸ëƒ¥"]):
        return "í—¤í—¤ ğŸ˜„ ë†ë‹´ë„ ì¢‹ì•„ìš”. ì´ì œ ë³¸ë¡ ìœ¼ë¡œâ€”ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    if "í…ŒìŠ¤íŠ¸" in t: return "ê°œë°œí•˜ëŠë¼ ê³ ìƒì´ ë§ì•„ìš”. ê·¸ë˜ë„ ëê¹Œì§€ íŒŒì´íŒ…!ğŸ’ª"
    return "ì•ˆë…•í•˜ì„¸ìš”! í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”. ë¯¼ì›/ìƒë‹´ ê´€ë ¨ë„ ì¢‹ê³ , ì¼ë°˜ì ì¸ ì§ˆë¬¸ë„ í™˜ì˜í•´ìš”."
  

# ---- í‚¤ì›Œë“œ â†’ (ìœ í˜•, ë²•ë¥ ) 1ì°¨ íŒíŠ¸ ----------------------------------------
def keyword_pairs_first(text: str, limit:int=5) -> List[Dict[str,str]]:
    hay = (text or "")
    out: List[Dict[str,str]] = []
    def add(u,l): out.append({"ìœ í˜•":u,"ê´€ë ¨ë²•ë¥ ":l})
    if any(k in hay for k in ["ì„±í¬ë¡±","ìŒë€","ìŒë‹´"]):
        add("ì„±í¬ë¡±/ìŒë€ë°œì–¸","ì„±í­ë ¥ë²”ì£„ì˜ ì²˜ë²Œ ë“±ì— ê´€í•œ íŠ¹ë¡€ë²• ì œ13ì¡°")
    if any(k in hay for k in ["ìš•ì„¤","í˜‘ë°•","í­ì–¸"]):
        add("í˜‘ë°•/í­í–‰(í­ì–¸) ê°€ëŠ¥ì„±","í˜•ë²• ì œ283ì¡°; í˜•ë²• ì œ260ì¡°")
    if any(k in hay for k in ["ëª¨ìš•","ëª…ì˜ˆí›¼ì†","í­ì–¸"]):
        add("ëª…ì˜ˆí›¼ì†Â·ëª¨ìš•Â·í­ì–¸","í˜•ë²• ì œ307ì¡°; í˜•ë²• ì œ311ì¡°")
    if "ì—…ë¬´ë°©í•´" in hay:
        add("ì—…ë¬´ë°©í•´","í˜•ë²• ì œ314ì¡°")
    if "ê°•ìš”" in hay:
        add("ê°•ìš”","í˜•ë²• ì œ324ì¡°")
    if any(k in hay for k in ["ì¥ë‚œì „í™”","ê´´ë¡­í˜"]):
        add("ì¥ë‚œì „í™”/ê²½ë²”","ê²½ë²”ì£„ì²˜ë²Œë²• ì œ3ì¡° ì œ1í•­ ì œ40í˜¸")
    if any(k in hay for k in ["ë°˜ë³µì ì¸ ë¯¼ì›"]):
        add("ë°˜ë³µ(ê³ ì§ˆ.ê°•ì„±ë¯¼ì›)","ê²½ë²”ì£„ì²˜ë²Œë²• ì œ3ì¡° ì œ1í•­ ì œ40í˜¸")
    if "ìŠ¤í† í‚¹" in hay:
        add("ìŠ¤í† í‚¹","ìŠ¤í† í‚¹ë²”ì£„ì˜ ì²˜ë²Œ ë“±ì— ê´€í•œ ë²•ë¥  ì œ18ì¡°")
    return out[:limit]
  
# ---- ë²•ë¥  ìš”ì•½ ì‚¬ì „ ---------------------------------------------------------
_LAW_BRIEFS = {
    "ì„±í­ë ¥ë²”ì£„ì˜ ì²˜ë²Œ ë“±ì— ê´€í•œ íŠ¹ë¡€ë²• ì œ13ì¡°": "í†µì‹ ìˆ˜ë‹¨ì„ ì´ìš©í•œ ì„±ì  ìˆ˜ì¹˜ì‹¬ ìœ ë°œ í–‰ìœ„ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤. (2ë…„ ì´í•˜ ì§•ì—­ ë˜ëŠ” 2ì²œë§Œì› ì´í•˜ ë²Œê¸ˆ)",
    "í˜•ë²• ì œ283ì¡°": "ìƒëŒ€ì—ê²Œ ê³µí¬ì‹¬ì„ ìœ ë°œí•˜ëŠ” í˜‘ë°• í–‰ìœ„ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤. (3ë…„ ì´í•˜ ì§•ì—­ ë˜ëŠ” 500ë§Œì› ì´í•˜ ë²Œê¸ˆ)",
    "í˜•ë²• ì œ260ì¡°": "ìƒëŒ€ë°© ì‹ ì²´ì— ëŒ€í•œ ìœ í˜•ë ¥ í–‰ì‚¬(í­í–‰)ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤. (2ë…„ ì´í•˜ ì§•ì—­ ë˜ëŠ” 500ë§Œì› ì´í•˜ ë²Œê¸ˆ)",
    "í˜•ë²• ì œ307ì¡°": "í—ˆìœ„/ì‚¬ì‹¤ ì ì‹œë¡œ íƒ€ì¸ì˜ ëª…ì˜ˆë¥¼ í›¼ì†í•˜ëŠ” í–‰ìœ„ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤. (2ë…„ ì´í•˜ ì§•ì—­ ë˜ëŠ” 500ë§Œì› ì´í•˜ ë²Œê¸ˆ)",
    "í˜•ë²• ì œ311ì¡°": "ê³µì—°í•œ ëª¨ìš•í–‰ìœ„ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤. (1ë…„ ì´í•˜ ì§•ì—­ ë˜ëŠ” 200ë§Œì› ì´í•˜ ë²Œê¸ˆ)",
    "í˜•ë²• ì œ314ì¡°": "ìœ„ë ¥ ê¸°íƒ€ ë°©ë²•ìœ¼ë¡œ íƒ€ì¸ì˜ ì—…ë¬´ë¥¼ ë°©í•´í•˜ëŠ” í–‰ìœ„ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤. (5ë…„ ì´í•˜ ì§•ì—­ ë˜ëŠ” 1ì²œ5ë°±ë§Œì› ì´í•˜ ë²Œê¸ˆ)",
    "í˜•ë²• ì œ324ì¡°": "í­í–‰/í˜‘ë°• ë“±ìœ¼ë¡œ ì˜ì‚¬ì— ë°˜í•´ ì˜ë¬´ ì—†ëŠ” ì¼ì„ í•˜ê²Œ í•˜ëŠ” ê°•ìš”ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤. (5ë…„ ì´í•˜ ì§•ì—­ ë˜ëŠ” 3ì²œë§Œì› ì´í•˜ ë²Œê¸ˆ)",
    "ê²½ë²”ì£„ì²˜ë²Œë²• ì œ3ì¡° ì œ1í•­ ì œ40í˜¸": "ì •ë‹¹í•œ ì´ìœ  ì—†ëŠ” ë°˜ë³µ ì „í™” ë“± ê´´ë¡­í˜ì„ ì œì¬í•©ë‹ˆë‹¤. (10ë§Œì› ì´í•˜ ë²Œê¸ˆÂ·êµ¬ë¥˜Â·ê³¼ë£Œ)",
    "ìŠ¤í† í‚¹ë²”ì£„ì˜ ì²˜ë²Œ ë“±ì— ê´€í•œ ë²•ë¥  ì œ18ì¡°": "ì§€ì†Â·ë°˜ë³µì  ìŠ¤í† í‚¹ ë²”ì£„ë¥¼ ì²˜ë²Œí•˜ê³  ë³´í˜¸ì¡°ì¹˜ë¥¼ ê·œì •í•©ë‹ˆë‹¤. (3ë…„ ì´í•˜ ì§•ì—­ ë˜ëŠ” 3ì²œë§Œì› ì´í•˜ ë²Œê¸ˆ)",
    "êµ­ë¯¼ê¶Œìµìœ„ì›íšŒ ìƒë‹´ì‚¬ ë³´í˜¸ ì§€ì¹¨": "ìƒë‹´ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ìš•ì„¤Â·í­ì–¸Â·ì„±í¬ë¡± ë“± ì•…Â·ê°•ì„± ë¯¼ì›ìœ¼ë¡œë¶€í„° ìƒë‹´ì‚¬ë¥¼ ë³´í˜¸í•˜ê¸° ìœ„í•´ ë§ˆë ¨ëœ ì œë„ì  ì§€ì¹¨ì…ë‹ˆë‹¤. ìƒë‹´ ì¢…ë£Œ ê¸°ì¤€, ê¸°ë¡ ê´€ë¦¬, ë³´í˜¸ ì¡°ì¹˜ ì ˆì°¨ ë“±ì„ ê·œì •í•©ë‹ˆë‹¤.",
}

def _brief_fallback_by_keyword(law: str) -> str:
    low = (law or "").lower()
    if "í˜‘ë°•" in low: return "í˜‘ë°• í–‰ìœ„ ì „ë°˜ì„ ì²˜ë²Œí•©ë‹ˆë‹¤."
    if "í­í–‰" in low: return "íƒ€ì¸ì— ëŒ€í•œ ìœ í˜•ë ¥ í–‰ì‚¬(í­í–‰)ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤."
    if "ëª¨ìš•" in low: return "ê³µì—°í•œ ëª¨ìš•ì„ ì²˜ë²Œí•©ë‹ˆë‹¤."
    if "ëª…ì˜ˆí›¼ì†" in low: return "í—ˆìœ„/ì‚¬ì‹¤ ì ì‹œ ëª…ì˜ˆí›¼ì†ì„ ì²˜ë²Œí•©ë‹ˆë‹¤."
    if "ì—…ë¬´ë°©í•´" in low: return "ì—…ë¬´ ìˆ˜í–‰ì„ ë°©í•´í•˜ëŠ” í–‰ìœ„ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤."
    if "ìŠ¤í† í‚¹" in low: return "ì§€ì†Â·ë°˜ë³µì  ìŠ¤í† í‚¹ì„ ì²˜ë²Œí•˜ê³  í”¼í•´ì ë³´í˜¸ë¥¼ ê·œì •í•©ë‹ˆë‹¤."
    if "ì„±í­ë ¥" in low or "ì´ìš©ìŒë€" in low or "í†µì‹ " in low: return "í†µì‹ ìˆ˜ë‹¨ì„ ì´ìš©í•œ ì„±ì  ìˆ˜ì¹˜ì‹¬ ìœ ë°œ í–‰ìœ„ë¥¼ ì²˜ë²Œí•©ë‹ˆë‹¤."
    return "ê´€ë ¨ í–‰ìœ„ë¥¼ ê·œìœ¨Â·ì œì¬í•˜ì—¬ í”¼í•´ ë°©ì§€ë¥¼ ë„ëª¨í•©ë‹ˆë‹¤."

def brief_for_law(law: str) -> str:
    return _LAW_BRIEFS.get(law, _brief_fallback_by_keyword(law))
  
# ---- ì •ê·œí™”/í›„ì²˜ë¦¬/í¬ë§· ------------------------------------------------------
def normalize_law_name(law: str) -> str:
    """
    ë²•ë¥ ëª… + ì¡°ë¬¸ë²ˆí˜¸ë§Œ ë‚¨ê¸°ê³  ê´„í˜¸/ì£¼ì„ì€ ì œê±°.
    ì˜ˆ: 'ë¯¼ì›ì²˜ë¦¬ë²• ì œ23ì¡° (3íšŒ ì´ìƒ ë°˜ë³µ ì‹œ ì¢…ê²°)' â†’ 'ë¯¼ì›ì²˜ë¦¬ë²• ì œ23ì¡°'
    """
    if not law: return ""
    return re.sub(r"\s*\(.*?\)", "", law).strip()

def _ok(v: str | None) -> bool:
    v = (v or "").strip()
    return bool(v) and v not in ("ì—†ìŒ","ì •ë³´ì—†ìŒ")

def post_filter_sources(sources: List[Dict], limit:int=3) -> List[Dict]:
    """
    - ';' ',' ë¡œ í•©ì³ì§„ ë²•ë¥  ë¶„í• 
    - ë²•ë¥ ëª…(ì •ê·œí™”) ê¸°ì¤€ dedup (ìœ í˜• ë‹¬ë¼ë„ ê°™ì€ ë²•ë¥ ì´ë©´ 1ê°œ)
    - 'ì—†ìŒ' ì œê±°, ìµœëŒ€ limit ìœ ì§€
    """
    out, seen = [], set()
    for e in sources or []:
        typ = (e.get("ìœ í˜•") or "").strip()
        raw = (e.get("ê´€ë ¨ë²•ë¥ ") or "").strip()
        if not (_ok(typ) and _ok(raw)): 
            continue
        # ì—¬ëŸ¬ ê°œê°€ í•œ ì¤„ì— ë“¤ì–´ì˜¤ëŠ” ê²½ìš° ë¶„í• 
        parts = [x.strip() for x in re.split(r"[;,]", raw) if x.strip()]
        for lw in parts:
            norm = normalize_law_name(lw)
            if not _ok(norm): 
                continue
            key = norm.lower()
            if key in seen: 
                continue
            seen.add(key)
            out.append({"ìœ í˜•": typ, "ê´€ë ¨ë²•ë¥ ": norm})
            if len(out) >= limit:
                return out
    return out

def format_sourcepages_text(sources: List[Dict]) -> str:
    blocks = []
    for e in sources or []:
        t = (e.get("ìœ í˜•") or "").strip()
        l = (e.get("ê´€ë ¨ë²•ë¥ ") or "").strip()
        if not t or not l: 
            continue
        blocks.append(f"- ìœ í˜•: {t}\n- ê´€ë ¨ë²•ë¥ : {l}")
    return "\n\n".join(blocks)



# ---- 2ë¬¸ë‹¨ ë³´ì • -------------------------------------------------------------
def build_second_paragraph(sources: List[Dict]) -> str:
    if not sources:
        return ("ë‹¹ì‹ ì´ ìƒë‹´í•œ ë‚´ìš©ì€ **â€˜í•´ë‹¹ ìœ í˜•â€™**ì— í•´ë‹¹í•  ìˆ˜ ìˆìœ¼ë©°, ê´€ë ¨ ë²•ë¥ ë¡œëŠ” **â€˜í•´ë‹¹ ë²•ë¥ â€™**ì´ ìˆìŠµë‹ˆë‹¤.\n"
                "ê° ë²•ë¥ ì˜ ì ìš©ì€ ìƒí™©ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ê¸°ê´€ ì§€ì¹¨ê³¼ ë²•ë¥  ìë¬¸ì„ í•¨ê»˜ ì°¸ê³ í•˜ì„¸ìš”.")
    typ = (sources[0].get("ìœ í˜•") or "í•´ë‹¹ ìœ í˜•").strip()
    laws, seen = [], set()
    for e in sources:
        l = (e.get("ê´€ë ¨ë²•ë¥ ") or "").strip()
        if not l or l in seen:
            continue
        seen.add(l)
        laws.append(l)
    head = f"ë‹¹ì‹ ì´ ìƒë‹´í•œ ë‚´ìš©ì€ **â€˜{typ}â€™**ì— í•´ë‹¹í•  ìˆ˜ ìˆìœ¼ë©°, ê´€ë ¨ ë²•ë¥ ë¡œëŠ” **â€˜" + "â€™, â€˜".join(laws) + "â€™**ê°€ ìˆìŠµë‹ˆë‹¤."
    # ë²•ë¥ ëª…ë§Œ êµµê²Œ
    bullets = "\n".join([f"- **{l}**: {brief_for_law(l)}" for l in laws])
    return head + "\n" + bullets

def ensure_two_paragraphs(answer: str, sources: List[Dict]) -> str:
    text = (answer or "").strip()
    paras = [p.strip() for p in text.split("\n\n") if p.strip()]
    if not paras:
        paras = ["ìƒí™© ê¸°ë¡, ì¦ê±° ë³´ì¡´, ìƒê¸‰ì ë³´ê³ , ì‹¬ë¦¬ ì•ˆì • í™•ë³´ ë“± ì¦‰ì‹œ ì¡°ì¹˜ë¥¼ ì§„í–‰í•˜ì„¸ìš”."]
    second = build_second_paragraph(sources)
    if len(paras) == 1:
        paras.append(second)
    else:
        paras[1] = second
    # 1ë¬¸ë‹¨ ë³´ê°•(4ë¬¸ì¥ ë¯¸ë§Œì´ë©´ ë³´ì¶©)
    sents = [s for s in re.split(r"[.ã€‚]\s*", paras[0]) if s.strip()]
    if len(sents) < 4:
        supplement = (" í†µí™” ì„ ì¢…ë£ŒÂ·ì°¨ë‹¨ ê¸°ì¤€ì„ ìˆ™ì§€í•˜ê³ , ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆë‚´ ë©˜íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
                      "ë‚´ë¶€ ì‹œìŠ¤í…œì— ì‹œê°„/ìƒí™©/ë°œì–¸ì„ êµ¬ì²´ ê¸°ë¡í•˜ê³  ì¦‰ì‹œ ë³´í˜¸ì¡°ì¹˜ë¥¼ ìš”ì²­í•˜ì„¸ìš”.")
        paras[0] = (paras[0] + supplement).strip()
    return "\n\n".join(paras)


# ---- ë³‘í•© ìš°ì„ ìˆœìœ„ ê·œì¹™(ë‹¨ì¼ ì§„ì‹¤ ì†ŒìŠ¤) ------------------------------------
# â€˜í‚¤ì›Œë“œ â†’ RAG â†’ ëª¨ë¸â€™ ìˆœìœ¼ë¡œ ë³‘í•© (ëª¨ë¸ì€ ë§ˆì§€ë§‰: í™˜ê° ê°€ëŠ¥ì„± ë•Œë¬¸)
def merge_sources(keyword_src: List[Dict], rag_src: List[Dict], model_src: List[Dict], limit:int=3) -> List[Dict]:
    merged = (keyword_src or []) + (rag_src or []) + (model_src or [])
    return post_filter_sources(merged, limit=limit)

# ---- JSON íŒŒì‹± ë³´ì • ----------------------------------------------------------
def parse_model_json(full_text: str) -> Tuple[str, List[Dict]]:
    """
    ëª¨ë¸ì´ JSONì„ ìŠ¤íŠ¸ë¦¼ ì¶œë ¥í–ˆì„ ë•Œ ìµœì¢… í•©ì¹˜ê¸° í›„ íŒŒì‹±.
    - ì‹¤íŒ¨ ì‹œ (ì›ë¬¸, []) ë°˜í™˜
    - ì„±ê³µ ì‹œ (answer, sourcePages[ì •ê·œí™”]) ë°˜í™˜
    """
    answer = full_text
    sources: List[Dict] = []
    try:
        parsed = json.loads(full_text)
        if isinstance(parsed, dict):
            if isinstance(parsed.get("answer"), str):
                answer = parsed["answer"]
            sp = parsed.get("sourcePages")
            if isinstance(sp, list):
                tmp = []
                for e in sp:
                    if not isinstance(e, dict): 
                        continue
                    t = (e.get("ìœ í˜•") or "").strip()
                    l = normalize_law_name((e.get("ê´€ë ¨ë²•ë¥ ") or "").strip())
                    if _ok(t) and _ok(l):
                        tmp.append({"ìœ í˜•": t, "ê´€ë ¨ë²•ë¥ ": l})
                sources = tmp
    except Exception:
        pass
    return answer, sources